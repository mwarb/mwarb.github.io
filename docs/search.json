[
  {
    "objectID": "publications/proceedings/hasan-humanlike-planning-2020.html",
    "href": "publications/proceedings/hasan-humanlike-planning-2020.html",
    "title": "Human-like planning for reaching in cluttered environments",
    "section": "",
    "text": "Humans, in comparison to robots, are remarkably adept at reaching for objects in cluttered environments. The best existing robot planners are based on random sampling of configuration space- which becomes excessively high-dimensional with large number of objects. Consequently, most planners often fail to efficiently find object manipulation plans in such environments. We addressed this problem by identifying high-level manipulation plans in humans, and transferring these skills to robot planners. We used virtual reality to capture human participants reaching for a target object on a tabletop cluttered with obstacles. From this, we devised a qualitative representation of the task space to abstract the decision making, irrespective of the number of obstacles. Based on this representation, human demonstrations were segmented and used to train decision classifiers. Using these classifiers, our planner produced a list of waypoints in task space. These waypoints provided a high-level plan, which could be transferred to an arbitrary robot model and used to initialise a local trajectory optimiser. We evaluated this approach through testing on unseen human VR data, a physics-based robot simulation, and a real robot (dataset and code are publicly available 1 ). We found that the human-like planner outperformed a state-of-the-art standard trajectory optimisation algorithm, and was able to generate effective strategies for rapid planning- irrespective of the number of obstacles in the environment."
  },
  {
    "objectID": "publications/proceedings/hasan-humanlike-planning-2020.html#abstract",
    "href": "publications/proceedings/hasan-humanlike-planning-2020.html#abstract",
    "title": "Human-like planning for reaching in cluttered environments",
    "section": "",
    "text": "Humans, in comparison to robots, are remarkably adept at reaching for objects in cluttered environments. The best existing robot planners are based on random sampling of configuration space- which becomes excessively high-dimensional with large number of objects. Consequently, most planners often fail to efficiently find object manipulation plans in such environments. We addressed this problem by identifying high-level manipulation plans in humans, and transferring these skills to robot planners. We used virtual reality to capture human participants reaching for a target object on a tabletop cluttered with obstacles. From this, we devised a qualitative representation of the task space to abstract the decision making, irrespective of the number of obstacles. Based on this representation, human demonstrations were segmented and used to train decision classifiers. Using these classifiers, our planner produced a list of waypoints in task space. These waypoints provided a high-level plan, which could be transferred to an arbitrary robot model and used to initialise a local trajectory optimiser. We evaluated this approach through testing on unseen human VR data, a physics-based robot simulation, and a real robot (dataset and code are publicly available 1 ). We found that the human-like planner outperformed a state-of-the-art standard trajectory optimisation algorithm, and was able to generate effective strategies for rapid planning- irrespective of the number of obstacles in the environment."
  },
  {
    "objectID": "publications/index.html",
    "href": "publications/index.html",
    "title": "Matthew Warburton",
    "section": "",
    "text": "Warburton, M., Campagnoli, C., Mon-Williams, M., Mushtaq, F. & Morehead, J. R. (2023). Visuomotor memory is not bound to visual motion. bioRxiv. doi: 10.1101/2023.09.27.559701 \n    \n    \n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n  \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications/index.html#preprints",
    "href": "publications/index.html#preprints",
    "title": "Matthew Warburton",
    "section": "",
    "text": "Warburton, M., Campagnoli, C., Mon-Williams, M., Mushtaq, F. & Morehead, J. R. (2023). Visuomotor memory is not bound to visual motion. bioRxiv. doi: 10.1101/2023.09.27.559701 \n    \n    \n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n  \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications/index.html#journal-articles-conference-proceedings",
    "href": "publications/index.html#journal-articles-conference-proceedings",
    "title": "Matthew Warburton",
    "section": "Journal articles & conference proceedings",
    "text": "Journal articles & conference proceedings\n\n\n\n  \n    \n        Warburton, M., Brookes, J., Hasan, M., Leonetti, M., Dogar, M., Wang, H., Cohn, A. G., Mushtaq, F., & Mon-Williams, M. (2024). Getting stuck in a rut as an emergent feature of a dynamic decision-making system. Royal Society Open Science, 11(4), 231550. doi: 10.1098/rsos.231550\n    \n    \n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n       Materials\n    \n    \n    \n  \n\n  \n    \n        Warburton, M., Wood, M. L., Sohal, K., Wright, J., Mon-Williams, M., & Atkinson, A. L. (2024). Risk of not being in employment, education or training (NEET) in late adolescence is signalled by school readiness measures at 4-5 years. BMC Public Health, 24. doi: 10.1186/s12889-024-18851-w\n    \n    \n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n       Materials\n    \n    \n    \n  \n\n  \n    \n        Warburton, M., Campagnoli, C., Mon-Williams, M., Mushtaq, F. & Morehead, J. R. (2023). Kinematic markers of skill in first-person shooter video games. PNAS Nexus, 2(8), pgad249 doi: 10.1093/pnasnexus/pgad249\n    \n    \n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n       Materials\n    \n    \n    \n  \n\n  \n    \n        Warburton, M., Mon-Williams, M., Mushtaq, F. & Morehead, J. R. (2023). Measuring motion-to-photon latency for sensorimotor experiments with virtual reality systems. Behavior Research Methods, 55, 3658-3678 doi: 10.3758/s13428-022-01983-5\n    \n    \n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n       Materials\n    \n    \n    \n  \n\n  \n    \n        Brookes, J., Warburton, M., Alghadier, M., Mon-Williams, M. & Mushtaq, F. (2020). Studying human behavior with virtual reality: The Unity Experiment Framework. Behavior Research Methods, 52, 455-463. doi: 10.3758/s13428-019-01242-0\n    \n    \n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n       Materials\n    \n    \n    \n  \n\n  \n    \n        Hasan, M., Warburton, M., Agboh, W. C., Dogar, M., Leonetti, M., Wang, H., Mushtaq, F., Mon-Williams, M. & Cohn, A. G. (2020). Human-like planning for reaching in cluttered environments. 2020 IEEE International Conference on Robotics and Automation (ICRA) (pp. 7784-7790). IEEE. doi: 10.1109/ICRA40945.2020.9196665.\n    \n    \n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n       Materials\n    \n    \n    \n  \n\n  \n    \n        Raw, R. K., Wilkie, R. M., Allen, R. J., Warburton, M., Leonetti, M., Williams, J. H. G. & Mon-Williams, M. (2019). Skill acquisition as a function of age, hand and task difficulty: Interactions between cognition and action. PLoS ONE, 14(2), e0211706 doi: 10.1371/journal.pone.0211706\n    \n    \n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n  \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications/index.html#reports",
    "href": "publications/index.html#reports",
    "title": "Matthew Warburton",
    "section": "Reports",
    "text": "Reports\n\n\n\n  \n    \n        N8 Research Partnership (2024). A country that works for all children and young people. An evidence-based plan for addressing the autism assessment and support crisis. Report. N8 Research Partnership. https://www.n8research.org.uk/media/CoTN_Autism_Report_1.pdf\n    \n    \n    \n      Details\n    \n    \n    \n      Link\n    \n    \n    \n    \n  \n\n  \n    \n        Mon-Williams, M., Wood, M., et al. (2023). Addressing Education and Health Inequity: Perspectives from the North of England. A report prepared for the Child of the North All-Party Parliamentary Group. Report. Child of the North. https://www.healthequitynorth.co.uk/app/uploads/APPG-REPORT-SEPT-23.pdf\n    \n    \n    \n      Details\n    \n    \n    \n      Link\n    \n    \n    \n    \n  \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications/articles/warburton-measuring-motion-2023.html",
    "href": "publications/articles/warburton-measuring-motion-2023.html",
    "title": "Measuring motion-to-photon latency for sensorimotor experiments with virtual reality systems",
    "section": "",
    "text": "Consumer virtual reality (VR) systems are increasingly being deployed in research to study sensorimotor behaviors, but properties of such systems require verification before being used as scientific tools. The ‘motion-to-photon’ latency (the lag between a user making a movement and the movement being displayed within the display) is a particularly important metric as temporal delays can degrade sensorimotor performance. Extant approaches to quantifying this measure have involved the use of bespoke software and hardware and produce a single measure of latency and ignore the effect of the motion prediction algorithms used in modern VR systems. This reduces confidence in the generalizability of the results. We developed a novel, system-independent, high-speed camera-based latency measurement technique to co-register real and virtual controller movements, allowing assessment of how latencies change through a movement. We applied this technique to measure the motion-to-photon latency of controller movements in the HTC Vive, Oculus Rift, Oculus Rift S, and Valve Index, using the Unity game engine and SteamVR. For the start of a sudden movement, all measured headsets had mean latencies between 21 and 42 ms. Once motion prediction could account for the inherent delays, the latency was functionally reduced to 2–13 ms, and our technique revealed that this reduction occurs within ~25–58 ms of movement onset. Our findings indicate that sudden accelerations (e.g., movement onset, impacts, and direction changes) will increase latencies and lower spatial accuracy. Our technique allows researchers to measure these factors and determine the impact on their experimental design before collecting sensorimotor data from VR systems."
  },
  {
    "objectID": "publications/articles/warburton-measuring-motion-2023.html#abstract",
    "href": "publications/articles/warburton-measuring-motion-2023.html#abstract",
    "title": "Measuring motion-to-photon latency for sensorimotor experiments with virtual reality systems",
    "section": "",
    "text": "Consumer virtual reality (VR) systems are increasingly being deployed in research to study sensorimotor behaviors, but properties of such systems require verification before being used as scientific tools. The ‘motion-to-photon’ latency (the lag between a user making a movement and the movement being displayed within the display) is a particularly important metric as temporal delays can degrade sensorimotor performance. Extant approaches to quantifying this measure have involved the use of bespoke software and hardware and produce a single measure of latency and ignore the effect of the motion prediction algorithms used in modern VR systems. This reduces confidence in the generalizability of the results. We developed a novel, system-independent, high-speed camera-based latency measurement technique to co-register real and virtual controller movements, allowing assessment of how latencies change through a movement. We applied this technique to measure the motion-to-photon latency of controller movements in the HTC Vive, Oculus Rift, Oculus Rift S, and Valve Index, using the Unity game engine and SteamVR. For the start of a sudden movement, all measured headsets had mean latencies between 21 and 42 ms. Once motion prediction could account for the inherent delays, the latency was functionally reduced to 2–13 ms, and our technique revealed that this reduction occurs within ~25–58 ms of movement onset. Our findings indicate that sudden accelerations (e.g., movement onset, impacts, and direction changes) will increase latencies and lower spatial accuracy. Our technique allows researchers to measure these factors and determine the impact on their experimental design before collecting sensorimotor data from VR systems."
  },
  {
    "objectID": "publications/articles/warburton-getting-stuck-2024.html",
    "href": "publications/articles/warburton-getting-stuck-2024.html",
    "title": "Getting stuck in a rut as an emergent feature of a dynamic decision-making system",
    "section": "",
    "text": "Human sensorimotor decision making has a tendency to get ‘stuck in a rut’, being biased towards selecting a previously implemented action structure (hysteresis). Existing explanations propose this is the consequence of an agent efficiently modifying an existing plan, rather than creating a new plan from scratch. Instead, we propose that hysteresis is an emergent property of a system learning from the consequences of its actions. To examine this, 152 participants moved a cursor to a target on a tablet device while avoiding an obstacle. Hysteresis was observed when the obstacle moved sequentially across the screen between trials, whereby the participant continued moving around the same side of the obstacle despite it now requiring a larger movement than the alternative. Two further experiments (n = 20) showed an attenuation when time and resource constraints were eased. We created a simple computational model capturing probabilistic estimate updating that showed the same patterns of results. This provides, to our knowledge, the first computational demonstration of how sensorimotor decision making can get ‘stuck in a rut’ through the updating of the probability estimates associated with actions."
  },
  {
    "objectID": "publications/articles/warburton-getting-stuck-2024.html#abstract",
    "href": "publications/articles/warburton-getting-stuck-2024.html#abstract",
    "title": "Getting stuck in a rut as an emergent feature of a dynamic decision-making system",
    "section": "",
    "text": "Human sensorimotor decision making has a tendency to get ‘stuck in a rut’, being biased towards selecting a previously implemented action structure (hysteresis). Existing explanations propose this is the consequence of an agent efficiently modifying an existing plan, rather than creating a new plan from scratch. Instead, we propose that hysteresis is an emergent property of a system learning from the consequences of its actions. To examine this, 152 participants moved a cursor to a target on a tablet device while avoiding an obstacle. Hysteresis was observed when the obstacle moved sequentially across the screen between trials, whereby the participant continued moving around the same side of the obstacle despite it now requiring a larger movement than the alternative. Two further experiments (n = 20) showed an attenuation when time and resource constraints were eased. We created a simple computational model capturing probabilistic estimate updating that showed the same patterns of results. This provides, to our knowledge, the first computational demonstration of how sensorimotor decision making can get ‘stuck in a rut’ through the updating of the probability estimates associated with actions."
  },
  {
    "objectID": "publications/articles/brookes-studying-human-2020.html",
    "href": "publications/articles/brookes-studying-human-2020.html",
    "title": "Getting stuck in a rut as an emergent feature of a dynamic decision-making system",
    "section": "",
    "text": "Virtual reality (VR) systems offer a powerful tool for human behavior research. The ability to create three-dimensional visual scenes and to measure responses to the visual stimuli enables the behavioral researcher to test hypotheses in a manner and scale that were previously unfeasible. For example, a researcher wanting to understand interceptive timing behavior might wish to violate Newtonian mechanics so that objects can move in novel 3-D trajectories. The same researcher might wish to collect such data with hundreds of participants outside the laboratory, and the use of a VR headset makes this a realistic proposition. The difficulty facing the researcher is that sophisticated 3-D graphics engines (e.g., Unity) have been created for game designers rather than behavioral scientists. To overcome this barrier, we have created a set of tools and programming syntaxes that allow logical encoding of the common experimental features required by the behavioral scientist. The Unity Experiment Framework (UXF) allows researchers to readily implement several forms of data collection and provides them with the ability to easily modify independent variables. UXF does not offer any stimulus presentation features, so the full power of the Unity game engine can be exploited. We use a case study experiment, measuring postural sway in response to an oscillating virtual room, to show that UXF can replicate and advance upon behavioral research paradigms. We show that UXF can simplify and speed up the development of VR experiments created in commercial gaming software and facilitate the efficient acquisition of large quantities of behavioral research data."
  },
  {
    "objectID": "publications/articles/brookes-studying-human-2020.html#abstract",
    "href": "publications/articles/brookes-studying-human-2020.html#abstract",
    "title": "Getting stuck in a rut as an emergent feature of a dynamic decision-making system",
    "section": "",
    "text": "Virtual reality (VR) systems offer a powerful tool for human behavior research. The ability to create three-dimensional visual scenes and to measure responses to the visual stimuli enables the behavioral researcher to test hypotheses in a manner and scale that were previously unfeasible. For example, a researcher wanting to understand interceptive timing behavior might wish to violate Newtonian mechanics so that objects can move in novel 3-D trajectories. The same researcher might wish to collect such data with hundreds of participants outside the laboratory, and the use of a VR headset makes this a realistic proposition. The difficulty facing the researcher is that sophisticated 3-D graphics engines (e.g., Unity) have been created for game designers rather than behavioral scientists. To overcome this barrier, we have created a set of tools and programming syntaxes that allow logical encoding of the common experimental features required by the behavioral scientist. The Unity Experiment Framework (UXF) allows researchers to readily implement several forms of data collection and provides them with the ability to easily modify independent variables. UXF does not offer any stimulus presentation features, so the full power of the Unity game engine can be exploited. We use a case study experiment, measuring postural sway in response to an oscillating virtual room, to show that UXF can replicate and advance upon behavioral research paradigms. We show that UXF can simplify and speed up the development of VR experiments created in commercial gaming software and facilitate the efficient acquisition of large quantities of behavioral research data."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Matthew Warburton",
    "section": "",
    "text": "Following an undergraduate degree in Mechanical Engineering (2012 - 2016), I completed a PhD in Psychology (2019 - 2024), and currently work as a Research Officer at the University of Leeds (2022 - Present).\nMy research interests include how we learn and maintain sensorimotor skills, how motor and cognitive abilities interact, and how early life factors influence learning trajectories. I have researched these areas using a variety of methods, including online experiments, virtual reality, and secondary data."
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Matthew Warburton",
    "section": "",
    "text": "Following an undergraduate degree in Mechanical Engineering (2012 - 2016), I completed a PhD in Psychology (2019 - 2024), and currently work as a Research Officer at the University of Leeds (2022 - Present).\nMy research interests include how we learn and maintain sensorimotor skills, how motor and cognitive abilities interact, and how early life factors influence learning trajectories. I have researched these areas using a variety of methods, including online experiments, virtual reality, and secondary data."
  },
  {
    "objectID": "index.html#recent-events",
    "href": "index.html#recent-events",
    "title": "Matthew Warburton",
    "section": "Recent events",
    "text": "Recent events\n\n2024-05-22: My paper investigating the association between a measure of school readiness and later NEET status was published in BMC Public Health."
  },
  {
    "objectID": "publications/articles/raw-skill-acquisition-2019.html",
    "href": "publications/articles/raw-skill-acquisition-2019.html",
    "title": "Skill acquisition as a function of age, hand and task difficulty: Interactions between cognition and action",
    "section": "",
    "text": "Some activities can be meaningfully dichotomised as ‘cognitive’ or ‘sensorimotor’ in nature—but many cannot. This has radical implications for understanding activity limitation in disability. For example, older adults take longer to learn the serial order of a complex sequence but also exhibit slower, more variable and inaccurate motor performance. So is their impaired skill acquisition a cognitive or motor deficit? We modelled sequence learning as a process involving a limited capacity buffer (working memory), where reduced performance restricts the number of elements that can be stored. To test this model, we examined the relationship between motor performance and sequence learning. Experiment 1 established that older adults were worse at learning the serial order of a complex sequence. Experiment 2 found that participants showed impaired sequence learning when the non-preferred hand was used. Experiment 3 confirmed that serial order learning is impaired when motor demands increase (as the model predicted). These results can be captured by reinforcement learning frameworks which suggest sequence learning will be constrained both by an individual’s sensorimotor ability and cognitive capacity."
  },
  {
    "objectID": "publications/articles/raw-skill-acquisition-2019.html#abstract",
    "href": "publications/articles/raw-skill-acquisition-2019.html#abstract",
    "title": "Skill acquisition as a function of age, hand and task difficulty: Interactions between cognition and action",
    "section": "",
    "text": "Some activities can be meaningfully dichotomised as ‘cognitive’ or ‘sensorimotor’ in nature—but many cannot. This has radical implications for understanding activity limitation in disability. For example, older adults take longer to learn the serial order of a complex sequence but also exhibit slower, more variable and inaccurate motor performance. So is their impaired skill acquisition a cognitive or motor deficit? We modelled sequence learning as a process involving a limited capacity buffer (working memory), where reduced performance restricts the number of elements that can be stored. To test this model, we examined the relationship between motor performance and sequence learning. Experiment 1 established that older adults were worse at learning the serial order of a complex sequence. Experiment 2 found that participants showed impaired sequence learning when the non-preferred hand was used. Experiment 3 confirmed that serial order learning is impaired when motor demands increase (as the model predicted). These results can be captured by reinforcement learning frameworks which suggest sequence learning will be constrained both by an individual’s sensorimotor ability and cognitive capacity."
  },
  {
    "objectID": "publications/articles/warburton-kinematic-markers-2023.html",
    "href": "publications/articles/warburton-kinematic-markers-2023.html",
    "title": "Kinematic markers of skill in first-person shooter video games",
    "section": "",
    "text": "Video games present a unique opportunity to study motor skill. First-person shooter (FPS) games have particular utility because they require visually guided hand movements that are similar to widely studied planar reaching tasks. However, there is a need to ensure the tasks are equivalent if FPS games are to yield their potential as a powerful scientific tool for investigating sensorimotor control. Specifically, research is needed to ensure that differences in visual feedback of a movement do not affect motor learning between the two contexts. In traditional tasks, a movement will translate a cursor across a static background, whereas FPS games use movements to pan and tilt the view of the environment. To this end, we designed an online experiment where participants used their mouse or trackpad to shoot targets in both visual contexts. Kinematic analysis showed player movements were nearly identical between contexts, with highly correlated spatial and temporal metrics. This similarity suggests a shared internal model based on comparing predicted and observed displacement vectors rather than primary sensory feedback. A second experiment, modeled on FPS-style aim-trainer games, found movements exhibited classic invariant features described within the sensorimotor literature. We found the spatial metrics tested were significant predictors of overall task performance. More broadly, these results show that FPS games offer a novel, engaging, and compelling environment to study sensorimotor skill, providing the same precise kinematic metrics as traditional planar reaching tasks."
  },
  {
    "objectID": "publications/articles/warburton-kinematic-markers-2023.html#abstract",
    "href": "publications/articles/warburton-kinematic-markers-2023.html#abstract",
    "title": "Kinematic markers of skill in first-person shooter video games",
    "section": "",
    "text": "Video games present a unique opportunity to study motor skill. First-person shooter (FPS) games have particular utility because they require visually guided hand movements that are similar to widely studied planar reaching tasks. However, there is a need to ensure the tasks are equivalent if FPS games are to yield their potential as a powerful scientific tool for investigating sensorimotor control. Specifically, research is needed to ensure that differences in visual feedback of a movement do not affect motor learning between the two contexts. In traditional tasks, a movement will translate a cursor across a static background, whereas FPS games use movements to pan and tilt the view of the environment. To this end, we designed an online experiment where participants used their mouse or trackpad to shoot targets in both visual contexts. Kinematic analysis showed player movements were nearly identical between contexts, with highly correlated spatial and temporal metrics. This similarity suggests a shared internal model based on comparing predicted and observed displacement vectors rather than primary sensory feedback. A second experiment, modeled on FPS-style aim-trainer games, found movements exhibited classic invariant features described within the sensorimotor literature. We found the spatial metrics tested were significant predictors of overall task performance. More broadly, these results show that FPS games offer a novel, engaging, and compelling environment to study sensorimotor skill, providing the same precise kinematic metrics as traditional planar reaching tasks."
  },
  {
    "objectID": "publications/articles/warburton-risk-of-2024.html",
    "href": "publications/articles/warburton-risk-of-2024.html",
    "title": "Risk of not being in employment, education or training (NEET) in late adolescence is signalled by school readiness measures at 4-5 years",
    "section": "",
    "text": "Not being in employment, education, or training (NEET) is associated with poor health (physical and mental) and social exclusion. We investigated whether England’s statutory school readiness measure conducted at 4-5 years provides a risk signal for NEET in late adolescence.\n\n\n\nWe identified 8,118 individuals with school readiness measures at 4-5 years and NEET records at 16-17 years using Connected Bradford, a bank of linked routinely collected datasets. Children were categorised as ‘school ready’ if they reached a ‘Good Level of Development’ on the Early Years Foundation Stage Profile. We used probit regression and structural equation modelling to investigate the relationship between school readiness and NEET status and whether it primarily relates to academic attainment.\n\n\n\nSchool readiness was significantly associated with NEET status. A larger proportion of young people who were not school ready were later NEET (11%) compared to those who were school ready (4%). Most of this effect was attributable to shared relationships with academic attainment, but there was also a direct effect. Measures of deprivation and Special Educational Needs were also strong predictors of NEET status.\n\n\n\nNEET risk factors occur early in life. School readiness measures could be used as early indicators of risk, with interventions targeted to prevent the long-term physical and mental health problems associated with NEET, especially in disadvantaged areas. Primary schools are therefore well placed to be public health partners in early intervention strategies."
  },
  {
    "objectID": "publications/articles/warburton-risk-of-2024.html#abstract",
    "href": "publications/articles/warburton-risk-of-2024.html#abstract",
    "title": "Risk of not being in employment, education or training (NEET) in late adolescence is signalled by school readiness measures at 4-5 years",
    "section": "",
    "text": "Not being in employment, education, or training (NEET) is associated with poor health (physical and mental) and social exclusion. We investigated whether England’s statutory school readiness measure conducted at 4-5 years provides a risk signal for NEET in late adolescence.\n\n\n\nWe identified 8,118 individuals with school readiness measures at 4-5 years and NEET records at 16-17 years using Connected Bradford, a bank of linked routinely collected datasets. Children were categorised as ‘school ready’ if they reached a ‘Good Level of Development’ on the Early Years Foundation Stage Profile. We used probit regression and structural equation modelling to investigate the relationship between school readiness and NEET status and whether it primarily relates to academic attainment.\n\n\n\nSchool readiness was significantly associated with NEET status. A larger proportion of young people who were not school ready were later NEET (11%) compared to those who were school ready (4%). Most of this effect was attributable to shared relationships with academic attainment, but there was also a direct effect. Measures of deprivation and Special Educational Needs were also strong predictors of NEET status.\n\n\n\nNEET risk factors occur early in life. School readiness measures could be used as early indicators of risk, with interventions targeted to prevent the long-term physical and mental health problems associated with NEET, especially in disadvantaged areas. Primary schools are therefore well placed to be public health partners in early intervention strategies."
  },
  {
    "objectID": "publications/preprints/warburton-visuomotor-memory-2023.html",
    "href": "publications/preprints/warburton-visuomotor-memory-2023.html",
    "title": "Visuomotor memory is not bound to visual motion",
    "section": "",
    "text": "Sensory feedback plays a critical role in motor control and motor learning, with both processes adjusting outgoing motor commands relative to the error between actual sensory feedback and the predictions of a forward model. However, models of motor control rarely specify the exact nature of these predictions. We hypothesized that large differences in low-level perceptual feedback would delineate contextual boundaries for motor memory, as sufficiently different feedback would require a distinct mapping between motor commands and sensory states. We tested this hypothesis by measuring transfer of visuomotor adaptation across contexts where hand movements caused visual motion in opposite directions (180° away). Instead of observing that visual feedback is bound to distinct internal models, we found nearly complete transfer of learning across the contexts. Finally, we found evidence that the motor memory was bound to the planned displacement of the hand, rather than visual features of the task space."
  },
  {
    "objectID": "publications/preprints/warburton-visuomotor-memory-2023.html#abstract",
    "href": "publications/preprints/warburton-visuomotor-memory-2023.html#abstract",
    "title": "Visuomotor memory is not bound to visual motion",
    "section": "",
    "text": "Sensory feedback plays a critical role in motor control and motor learning, with both processes adjusting outgoing motor commands relative to the error between actual sensory feedback and the predictions of a forward model. However, models of motor control rarely specify the exact nature of these predictions. We hypothesized that large differences in low-level perceptual feedback would delineate contextual boundaries for motor memory, as sufficiently different feedback would require a distinct mapping between motor commands and sensory states. We tested this hypothesis by measuring transfer of visuomotor adaptation across contexts where hand movements caused visual motion in opposite directions (180° away). Instead of observing that visual feedback is bound to distinct internal models, we found nearly complete transfer of learning across the contexts. Finally, we found evidence that the motor memory was bound to the planned displacement of the hand, rather than visual features of the task space."
  }
]